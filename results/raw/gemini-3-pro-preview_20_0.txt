{'reasoning': "To satisfy the requirement of handling datasets ranging from 10 to 200,000 holes efficiently on a 12-core machine within 5 minutes, the solution utilizes a Data-Oriented Design (Structure of Arrays) for cache efficiency. \n\n1. **Spatial Indexing**: A 'Sparse Grid' implemented as a sorted array of `(CellCoordinate, SampleIndex)` tuples is used. This allows neighbor lookups via binary search (O(log N)) without the overhead of HashMaps, which is critical for scaling to millions of points.\n2. **Outlier Detection**: The algorithm uses the Median Absolute Deviation (MAD), a robust statistical measure, to calculate a modified Z-score for each sample compared to its spatial neighbors. This is resistant to the influence of other outliers in the same vicinity.\n3. **Parallelism**: The workload is split into chunks processed by a thread pool (using `std::thread`), leveraging the 12 cores to calculate neighbors and scores in parallel.\n4. **Adaptability**: The grid cell size is dynamically calculated based on the dataset's bounding box and density, ensuring the algorithm adapts whether the survey is a dense localized cluster or a sparse regional exploration.", 'rust_code': 'use std::cmp::Ordering;\nuse std::collections::BinaryHeap;\nuse std::io::{self, BufRead, Write};\nuse std::sync::{Arc, Mutex};\nuse std::thread;\nuse std::time::Instant;\n\n// --- Data Structures ---\n\n// Structure of Arrays (SoA) for cache-friendly access\nstruct DataSet {\n    hole_ids: Vec<String>,\n    property_names: Vec<String>,\n    \n    // Flat vectors for all samples across all holes\n    // coords: [x0, y0, z0, x1, y1, z1, ...]\n    coords: Vec<f32>,\n    // properties: [p0_s0, p1_s0, ..., p0_s1, p1_s1, ...]\n    properties: Vec<f32>,\n    // Map sample_index -> (hole_idx, sample_idx_in_hole)\n    meta: Vec<(u32, u32)>,\n}\n\nstruct Suspect {\n    hole_id_idx: u32,\n    sample_idx: u32,\n    prop_idx: usize,\n    confidence: f32,\n}\n\n// Spatial Index: Sorted list of (CellKey, SampleIndex)\ntype CellKey = (i32, i32, i32);\nstruct SpatialGrid {\n    cells: Vec<(CellKey, u32)>,\n    cell_size: f32,\n}\n\nimpl SpatialGrid {\n    fn new(coords: &[f32], total_samples: usize) -> Self {\n        // 1. Calculate Bounding Box\n        let mut min_x = f32::MAX; let mut max_x = f32::MIN;\n        let mut min_y = f32::MAX; let mut max_y = f32::MIN;\n        let mut min_z = f32::MAX; let mut max_z = f32::MIN;\n\n        for i in 0..total_samples {\n            let x = coords[i*3];\n            let y = coords[i*3+1];\n            let z = coords[i*3+2];\n            if x < min_x { min_x = x; }\n            if x > max_x { max_x = x; }\n            if y < min_y { min_y = y; }\n            if y > max_y { max_y = y; }\n            if z < min_z { min_z = z; }\n            if z > max_z { max_z = z; }\n        }\n\n        // 2. Determine Cell Size\n        // Heuristic: Volume per sample. \n        // We want a cell to contain approx local neighborhood (e.g., 20-50 samples)\n        // But for outlier detection, we need neighbors within a reasonable radius.\n        // If data is linear (1D holes), density calc can be skewed. \n        // We use a robust heuristic: (Volume / N)^(1/3) * scalar\n        let width = (max_x - min_x).max(1.0);\n        let height = (max_y - min_y).max(1.0);\n        let depth = (max_z - min_z).max(1.0);\n        let volume = width * height * depth;\n        \n        // Avoid div by zero or extreme values\n        let density_linear = (volume / (total_samples as f32)).powf(1.0/3.0);\n        // Multiplier 3.0 usually captures enough neighbors in a 3x3x3 grid search\n        let cell_size = if density_linear.is_nan() || density_linear == 0.0 { 10.0 } else { density_linear * 3.0 };\n\n        // 3. Assign Cells\n        let mut cells = Vec::with_capacity(total_samples);\n        for i in 0..total_samples {\n            let x = coords[i*3];\n            let y = coords[i*3+1];\n            let z = coords[i*3+2];\n            let kx = (x / cell_size).floor() as i32;\n            let ky = (y / cell_size).floor() as i32;\n            let kz = (z / cell_size).floor() as i32;\n            cells.push(((kx, ky, kz), i as u32));\n        }\n\n        // 4. Sort for Binary Search\n        cells.sort_unstable_by(|a, b| a.0.cmp(&b.0));\n\n        SpatialGrid {\n            cells,\n            cell_size,\n        }\n    }\n\n    fn get_potential_neighbors(&self, x: f32, y: f32, z: f32, neighbors: &mut Vec<u32>) {\n        let kx = (x / self.cell_size).floor() as i32;\n        let ky = (y / self.cell_size).floor() as i32;\n        let kz = (z / self.cell_size).floor() as i32;\n\n        // Search 3x3x3 neighborhood\n        for dx in -1..=1 {\n            for dy in -1..=1 {\n                for dz in -1..=1 {\n                    let key = (kx + dx, ky + dy, kz + dz);\n                    \n                    // Binary search for the start of this key\n                    let start_idx = self.cells.partition_point(|&c| c.0 < key);\n                    \n                    if start_idx < self.cells.len() && self.cells[start_idx].0 == key {\n                        // Iterate until key changes\n                        let mut i = start_idx;\n                        while i < self.cells.len() && self.cells[i].0 == key {\n                            neighbors.push(self.cells[i].1);\n                            i += 1;\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n// --- Main Logic ---\n\nfn main() {\n    // 1. Read and Parse Input\n    let data = match read_input() {\n        Ok(d) => Arc::new(d),\n        Err(e) => {\n            eprintln!("Error reading input: {}", e);\n            return;\n        }\n    };\n\n    let total_samples = data.meta.len();\n    if total_samples == 0 {\n        println!("0");\n        return;\n    }\n\n    // 2. Build Spatial Grid\n    let grid = Arc::new(SpatialGrid::new(&data.coords, total_samples));\n\n    // 3. Parallel Processing\n    let num_threads = std::thread::available_parallelism().map(|n| n.get()).unwrap_or(4);\n    let chunk_size = (total_samples + num_threads - 1) / num_threads;\n    let results = Arc::new(Mutex::new(Vec::new()));\n\n    let mut handles = vec![];\n\n    for i in 0..num_threads {\n        let data_ref = Arc::clone(&data);\n        let grid_ref = Arc::clone(&grid);\n        let results_ref = Arc::clone(&results);\n        \n        let start = i * chunk_size;\n        let end = std::cmp::min((i + 1) * chunk_size, total_samples);\n\n        if start >= total_samples {\n            break;\n        }\n\n        handles.push(thread::spawn(move || {\n            let mut local_suspects = Vec::new();\n            let num_props = data_ref.property_names.len();\n            let mut neighbor_indices = Vec::with_capacity(200);\n            let mut neighbor_vals = Vec::with_capacity(200);\n\n            for idx in start..end {\n                // Get coordinates\n                let px = data_ref.coords[idx * 3];\n                let py = data_ref.coords[idx * 3 + 1];\n                let pz = data_ref.coords[idx * 3 + 2];\n\n                // Find neighbors\n                neighbor_indices.clear();\n                grid_ref.get_potential_neighbors(px, py, pz, &mut neighbor_indices);\n\n                // Check each property\n                for p_idx in 0..num_props {\n                    let val = data_ref.properties[idx * num_props + p_idx];\n                    if val.is_nan() { continue; }\n\n                    neighbor_vals.clear();\n                    \n                    // Collect valid neighbor values\n                    for &n_idx in &neighbor_indices {\n                        if n_idx as usize == idx { continue; } // Skip self\n\n                        // Optional: distance check to refine grid results (circle vs square)\n                        let nx = data_ref.coords[n_idx as usize * 3];\n                        let ny = data_ref.coords[n_idx as usize * 3 + 1];\n                        let nz = data_ref.coords[n_idx as usize * 3 + 2];\n                        let dist_sq = (px-nx)*(px-nx) + (py-ny)*(py-ny) + (pz-nz)*(pz-nz);\n                        \n                        // Only consider actual close neighbors (e.g. within cell_size distance)\n                        // Using grid.cell_size as radius\n                        if dist_sq <= (grid_ref.cell_size * grid_ref.cell_size) {\n                            let n_val = data_ref.properties[n_idx as usize * num_props + p_idx];\n                            if !n_val.is_nan() {\n                                neighbor_vals.push(n_val);\n                            }\n                        }\n                    }\n\n                    if neighbor_vals.len() < 5 {\n                        // Not enough data to judge\n                        continue;\n                    }\n\n                    // Calculate Median\n                    // Quick select or sort\n                    let mid = neighbor_vals.len() / 2;\n                    // Utilize `select_nth_unstable` for O(N) median finding\n                    neighbor_vals.select_nth_unstable_by(mid, |a, b| a.partial_cmp(b).unwrap_or(Ordering::Equal));\n                    let median = neighbor_vals[mid];\n\n                    // Calculate MAD (Median Absolute Deviation)\n                    let mut deviations: Vec<f32> = neighbor_vals.iter()\n                        .map(|v| (v - median).abs())\n                        .collect();\n                    \n                    let mid_dev = deviations.len() / 2;\n                    deviations.select_nth_unstable_by(mid_dev, |a, b| a.partial_cmp(b).unwrap_or(Ordering::Equal));\n                    let mad = deviations[mid_dev];\n\n                    // Standard consistency constant for normal distribution\n                    let sigma = 1.4826 * mad;\n\n                    // Avoid division by zero (noise floor)\n                    let noise_floor = 1e-6;\n                    let z_score = (val - median).abs() / (sigma + noise_floor);\n\n                    // Threshold: 4.0 is a strong outlier\n                    if z_score > 4.0 {\n                         local_suspects.push(Suspect {\n                             hole_id_idx: data_ref.meta[idx].0,\n                             sample_idx: data_ref.meta[idx].1,\n                             prop_idx: p_idx,\n                             confidence: z_score,\n                         });\n                    }\n                }\n            }\n            \n            let mut global = results_ref.lock().unwrap();\n            global.append(&mut local_suspects);\n        }));\n    }\n\n    for h in handles {\n        h.join().unwrap();\n    }\n\n    // 4. Sort and Output\n    let mut all_suspects = match Arc::try_unwrap(results) {\n        Ok(mutex) => mutex.into_inner().unwrap(),\n        Err(_) => panic!("Lock error"),\n    };\n\n    // Sort by confidence descending\n    all_suspects.sort_by(|a, b| b.confidence.partial_cmp(&a.confidence).unwrap_or(Ordering::Equal));\n\n    println!("{}", all_suspects.len());\n    let stdout = io::stdout();\n    let mut handle = stdout.lock();\n\n    for s in all_suspects {\n        writeln!(handle, "{} {} {} {:.4}", \n            data.hole_ids[s.hole_id_idx as usize], \n            s.sample_idx, \n            data.property_names[s.prop_idx], \n            s.confidence\n        ).unwrap();\n    }\n}\n\nfn read_input() -> io::Result<DataSet> {\n    // Using simple token parsing from stdin\n    // Reading everything to string is faster for parsing in memory than many small reads\n    let mut buffer = String::new();\n    io::stdin().read_to_string(&mut buffer)?;\n    let mut tokens = buffer.split_whitespace();\n\n    let num_holes: usize = tokens.next().unwrap_or("0").parse().unwrap_or(0);\n    let num_props: usize = tokens.next().unwrap_or("0").parse().unwrap_or(0);\n\n    let mut prop_names = Vec::new();\n    for _ in 0..num_props {\n        prop_names.push(tokens.next().unwrap_or("unknown").to_string());\n    }\n\n    let mut hole_ids = Vec::with_capacity(num_holes);\n    let mut coords = Vec::new(); // will reserve lazily\n    let mut properties = Vec::new();\n    let mut meta = Vec::new();\n\n    // Heuristic reservation\n    coords.reserve(num_holes * 100 * 3);\n    properties.reserve(num_holes * 100 * num_props);\n    meta.reserve(num_holes * 100);\n\n    for h_idx in 0..num_holes {\n        let hole_id = tokens.next().unwrap().to_string();\n        let sx: f32 = tokens.next().unwrap().parse().unwrap();\n        let sy: f32 = tokens.next().unwrap().parse().unwrap();\n        let sz: f32 = tokens.next().unwrap().parse().unwrap();\n        let dx: f32 = tokens.next().unwrap().parse().unwrap();\n        let dy: f32 = tokens.next().unwrap().parse().unwrap();\n        let dz: f32 = tokens.next().unwrap().parse().unwrap();\n        let _len: f32 = tokens.next().unwrap().parse().unwrap(); // unused\n        let num_samples: usize = tokens.next().unwrap().parse().unwrap();\n\n        hole_ids.push(hole_id);\n\n        for _ in 0..num_samples {\n            let depth: f32 = tokens.next().unwrap().parse().unwrap();\n            \n            // Calculate absolute 3D coord\n            let wx = sx + dx * depth;\n            let wy = sy + dy * depth;\n            let wz = sz + dz * depth;\n            \n            coords.push(wx);\n            coords.push(wy);\n            coords.push(wz);\n\n            for _ in 0..num_props {\n                let val_str = tokens.next().unwrap();\n                // Handle potential missing data if labeled as something non-numeric (though prompt implies floats)\n                let val = val_str.parse::<f32>().unwrap_or(f32::NAN);\n                properties.push(val);\n            }\n            \n            // Store sample index from input if needed, but input format doesn\'t explicitly give an index ID,\n            // just sequential order. We\'ll use 0-based index.\n            // Wait, Output format requires `sample_idx`? \n            // "hole_id sample_idx property_name confidence"\n            // I will assume sample_idx is the line number within the hole (0-based or depth?)\n            // Usually index. I will use 1-based index to match common drillhole logs, or 0.\n            // Let\'s use 0-based index corresponding to order in input.\n            let current_sample_idx = (meta.len() - (meta.len() / (num_samples.max(1) + 999999) ) * 0) as u32; \n            // Actually just track count within hole\n        }\n\n        // Fix meta generation: we just pushed `num_samples` entries. \n        // We need to add them to meta now. Since we are in the loop, we can\'t easily.\n        // Actually, we can just push to meta inside the sample loop.\n    }\n    \n    // Clear and rebuild meta properly to match vector sizes\n    // Re-reading logic slightly to fix meta push\n    // (The previous loop logic was slightly mingled)\n    \n    // Let\'s reset and do it cleanly with iterator\n    // Since we consumed the iterator, we can\'t reset. \n    // I will rewrite the inner loop logic above to be correct.\n    \n    // Correct logic:\n    // We are consuming `tokens` sequentially. \n    // We need to track `meta` correctly.\n    \n    // Reset vectors (simulated)\n    hole_ids.clear();\n    coords.clear();\n    properties.clear();\n    meta.clear();\n    \n    // Re-create tokens iterator from buffer (cannot rewind split_whitespace easily)\n    // So I will just implement the correct logic in a fresh block below assuming the code above was scratchpad.\n    \n    let mut tokens = buffer.split_whitespace();\n    let num_holes: usize = tokens.next().unwrap_or("0").parse().unwrap_or(0);\n    let num_props: usize = tokens.next().unwrap_or("0").parse().unwrap_or(0);\n    \n    let mut prop_names = Vec::new();\n    for _ in 0..num_props {\n        prop_names.push(tokens.next().unwrap_or("unknown").to_string());\n    }\n    \n    for h_idx in 0..num_holes {\n         let hole_id = tokens.next().unwrap().to_string();\n         hole_ids.push(hole_id);\n         \n         let sx: f32 = tokens.next().unwrap().parse().unwrap();\n         let sy: f32 = tokens.next().unwrap().parse().unwrap();\n         let sz: f32 = tokens.next().unwrap().parse().unwrap();\n         let dx: f32 = tokens.next().unwrap().parse().unwrap();\n         let dy: f32 = tokens.next().unwrap().parse().unwrap();\n         let dz: f32 = tokens.next().unwrap().parse().unwrap();\n         let _len: f32 = tokens.next().unwrap().parse().unwrap();\n         let num_samples: usize = tokens.next().unwrap().parse().unwrap();\n         \n         for s_idx in 0..num_samples {\n             let depth: f32 = tokens.next().unwrap().parse().unwrap();\n             let wx = sx + dx * depth;\n             let wy = sy + dy * depth;\n             let wz = sz + dz * depth;\n             \n             coords.push(wx);\n             coords.push(wy);\n             coords.push(wz);\n             \n             for _ in 0..num_props {\n                 let val = tokens.next().unwrap().parse::<f32>().unwrap_or(f32::NAN);\n                 properties.push(val);\n             }\n             \n             meta.push((h_idx as u32, s_idx as u32));\n         }\n    }\n\n    Ok(DataSet {\n        hole_ids,\n        property_names: prop_names,\n        coords,\n        properties,\n        meta,\n    })\n}\n'}